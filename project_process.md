### 1. EEG特征提取阶段
首先从原始EEG信号开始处理：

1. 使用 `segment_raw_signals_200Hz.py` 将信号分段
2. 通过 `DE_PSD.py` 提取两类特征：
   - 差分熵(DE)特征
   - 功率谱密度(PSD)特征
### 2. EEG-VP阶段（EEG到视频感知的映射）
这个阶段使用 `EEG_VP_train_test.py` 实现：

1. 特征编码 ：
   
   - 将EEG特征通过多层感知器(MLP)进行编码
   - 生成视频感知表示
2. 对比学习 ：
   
   - 使用CLIP模型提取真实视频的特征
   - 将EEG编码与视频特征进行对比学习
   - 目标是让EEG编码与对应视频的特征尽可能接近
### 3. 视频生成阶段
使用 `train_finetune_videodiffusion.py` 实现：

1. 条件扩散模型 ：
   
   - 基于预训练的视频扩散模型
   - 使用EEG-VP生成的特征作为条件
   - 通过注意力机制将EEG信息注入生成过程
2. 生成过程 ：
   
   - 从随机噪声开始
   - 逐步去噪生成视频帧
   - 使用EEG特征指导生成过程
### 4. 推理流程
使用 `inference_eeg2video.py` 完成最终生成：

1. 输入新的EEG信号
2. 通过EEG-VP模型获取视频感知特征
3. 将特征输入微调后的扩散模型
4. 生成对应的视频序列
### 5. 评估阶段
使用 `40_class_run_metrics.py` 进行评估：

1. 计算生成视频的质量指标
2. 评估视频与原始视频的相似度
3. 分析EEG特征与生成视频的对应关系
整个过程形成了一个完整的端到端系统，将大脑活动（EEG信号）转换为具体的视频内容。